{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /kaggle/working/Compression-Framework-for-EdgeAI\n!git clone https://github.com/ha405/Compression-Framework-for-EdgeAI","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run the below command only once per session. If you reset session run again. ","metadata":{}},{"cell_type":"code","source":"!pip install -r /kaggle/working/Compression-Framework-for-EdgeAI/requirements.txt\n!pip install logbar\n!pip install tokenicer\n!pip install device_smi\n!pip install random_word\n!pip install datasets","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nimport os\nlibrary_path = \"/kaggle/working/Compression-Framework-for-EdgeAI/KLAWQ\" \nif library_path not in sys.path:\n     sys.path.insert(0, library_path)\n     print(f\"Added '{library_path}' to sys.path\")\nfrom quant import GPTQModel, QuantizeConfig ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport torch\nimport shutil\nimport math\nimport pandas as pd\nfrom transformers import AutoTokenizer\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## WikiText-2","metadata":{}},{"cell_type":"code","source":"\n\ndataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n\ntrain_dataset = dataset[\"train\"]\nval_dataset = dataset[\"validation\"]\ntest_dataset = dataset[\"test\"]\n\ncalibration_dataset = train_dataset.select(range(1000))\n\ndataset_splits = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset,\n    \"calibration\": calibration_dataset,\n})\n\nprint({k: len(v) for k, v in dataset_splits.items()})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To Clear GPU Cache","metadata":{}},{"cell_type":"code","source":"def clear_gpu_cache():\n    gc.collect()  \n    torch.cuda.empty_cache()  \n    torch.cuda.ipc_collect()  \n    print(\"✅ GPU VRAM and cache cleared.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quantization Functions","metadata":{}},{"cell_type":"code","source":"def clear_quant_path(path=None):\n    if path and os.path.exists(path):\n        shutil.rmtree(path)\n    torch.cuda.empty_cache()\n    gc.collect()\n\ndef quantize_and_eval(model_id, calib_tokenized, eval_texts, beta, tau, quant_path, batch_size=8):\n    print(f\"  -> [Quantize] beta={beta}, tau={tau}\")\n    clear_quant_path(quant_path)\n\n    # 1) Quantize\n    quant_cfg = QuantizeConfig(bits=4, group_size=-1, beta=beta, tau=tau)\n    model = GPTQModel.load(model_id, quant_cfg, trust_remote_code=True)\n    model.quantize(calib_tokenized, batch_size=batch_size)\n    os.makedirs(os.path.dirname(quant_path), exist_ok=True)\n    model.save(quant_path)\n    print(f\"     Quantization complete and saved to {quant_path}\")\n\n    clear_quant_path()  # clear GPU/cache before loading\n\n    # 2) Load quantized model\n    model = GPTQModel.from_pretrained(\n        quant_path,\n        trust_remote_code=True,\n        device_map=\"auto\",\n        quantize_config=quant_cfg\n    )\n    model.eval()\n\n    # 3) Tokenize evaluation texts using the tokenizer defined outside\n    encodings = tokenizer(\n        eval_texts,\n        return_tensors=\"pt\",\n        padding=\"longest\",\n        truncation=True,\n        max_length=max_len\n    )\n    input_ids = encodings.input_ids.to(model.device)\n    attention_mask = encodings.attention_mask.to(model.device)\n\n    # 4) Compute loss & perplexity\n    losses = []\n    with torch.no_grad():\n        for i in range(0, len(eval_texts), batch_size):\n            b_ids  = input_ids[i:i+batch_size]\n            b_mask = attention_mask[i:i+batch_size]\n            out    = model(input_ids=b_ids, attention_mask=b_mask, labels=b_ids)\n            losses.append(out.loss.item())\n\n    avg_loss = sum(losses) / len(losses)\n    perplexity = math.exp(avg_loss)\n    print(f\"     Eval complete: loss={avg_loss:.4f}, ppl={perplexity:.2f}\")\n\n    # Clean up\n    del model\n    clear_quant_path(quant_path)\n\n    return avg_loss, perplexity","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"calib_texts = dataset_splits[\"calibration\"][\"text\"]\neval_texts  = [t for t in dataset_splits[\"validation\"][\"text\"] if t.strip()][:3000]\n\n# --- init tokenizer & pre-tokenize calibration set ---\nmodel_id = \"meta-llama/Llama-2-7b-hf\"\ntokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token\nmax_len = tokenizer.model_max_length\n\ncalib_tokenized = tokenizer(\n    calib_texts,\n    truncation=True,\n    padding=\"longest\",\n    max_length=max_len,\n    return_tensors=\"pt\"\n)\n\nbase_quant_path = \"/kaggle/working/llama2-7b-quant\"\nbeta_values     = [0.2, 0.4, 0.6, 0.8, 1.0]\ntau_values      = [0.5, 1.0, 1.5, 2.0]\nresults = []\ntotal_iters = len(beta_values) + len(tau_values)\niter_count = 0\n\n\nfor beta in beta_values:\n    iter_count += 1\n    print(f\"[Iter {iter_count}/{total_iters}] β={beta}, τ=0.5\")\n    qp = f\"{base_quant_path}-b{beta}-t0.5\"\n    loss, ppl = quantize_and_eval(model_id, calib_tokenized, eval_texts, beta, 0.5, qp)\n    results.append({\"beta\": beta, \"tau\": 0.5, \"loss\": loss, \"ppl\": ppl})\n\n# select best β at τ=0.5\nbest_beta = min(r for r in results if r[\"tau\"] == 0.5, key=lambda x: x[\"ppl\"])[\"beta\"]\nprint(f\"[Sweep] Best β @ τ=0.5: {best_beta}\")\n\n# τ sweep at best β\nfor tau in tau_values:\n    iter_count += 1\n    print(f\"[Iter {iter_count}/{total_iters}] β={best_beta}, τ={tau}\")\n    qp = f\"{base_quant_path}-b{best_beta}-t{tau}\"\n    loss, ppl = quantize_and_eval(model_id, calib_tokenized, eval_texts, best_beta, tau, qp)\n    results.append({\"beta\": best_beta, \"tau\": tau, \"loss\": loss, \"ppl\": ppl})\n\ndf = pd.DataFrame(results)\nprint(df.to_markdown(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plotting","metadata":{}},{"cell_type":"code","source":"df2 = pd.DataFrame(results2)\n\n# Constants\nconst_tau = 0.5\ndf_beta = df[df['tau'] == const_tau].reset_index(drop=True)\n\nbest_beta = df_beta.loc[df_beta['ppl'].idxmin(), 'beta']\ndf_tau = df[df['beta'] == best_beta].reset_index(drop=True)\n\ndef plot_zoomed_bar(x, y, xlabel, ylabel, title, cmap):\n    colors = cmap(np.linspace(0, 1, len(x)))\n    fig, ax = plt.subplots(figsize=(8, 4))\n    bars = ax.bar(x, y, color=colors, edgecolor='black', linewidth=0.8)\n\n    ax.set_title(title, fontsize=14)\n    ax.set_xlabel(xlabel, fontsize=12)\n    ax.set_ylabel(ylabel, fontsize=12)\n    ax.grid(axis='y', linestyle='--', alpha=0.6)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n\n    y_min, y_max = y.min(), y.max()\n    margin = (y_max - y_min) * 0.15\n    ax.set_ylim(y_min - margin, y_max + margin)\n    \n    plt.tight_layout()\n\nplot_zoomed_bar(\n    x=df_beta['beta'].astype(str),\n    y=df_beta['ppl'],\n    xlabel='β (Beta values)',\n    ylabel='Perplexity',\n    title='Perplexity vs Beta @ τ = 0.5',\n    cmap=plt.cm.Set2\n)\n\nplot_zoomed_bar(\n    x=df_beta['beta'].astype(str),\n    y=df_beta['loss'],\n    xlabel='β (Beta values)',\n    ylabel='Avg NLL Loss',\n    title='Loss vs Beta @ τ = 0.5',\n    cmap=plt.cm.Pastel1\n)\n\nplot_zoomed_bar(\n    x=df_tau['tau'].astype(str),\n    y=df_tau['ppl'],\n    xlabel='τ (Tau values)',\n    ylabel='Perplexity',\n    title=f'Perplexity vs Tau @ β = {best_beta}',\n    cmap=plt.cm.Pastel2\n)\n\nplot_zoomed_bar(\n    x=df_tau['tau'].astype(str),\n    y=df_tau['loss'],\n    xlabel='τ (Tau values)',\n    ylabel='Avg NLL Loss',\n    title=f'Loss vs Tau @ β = {best_beta}',\n    cmap=plt.cm.Dark2\n)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}