{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pez2XUkkKl3h"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9dhWrEgKl3j"
      },
      "outputs": [],
      "source": [
        "hamzai3_gptq_2_path = kagglehub.dataset_download('hamzai3/gptq-2')\n",
        "hamzai3_gptq_6_path = kagglehub.dataset_download('hamzai3/gptq-6')\n",
        "hamzai3_gptq_default_path = kagglehub.dataset_download('hamzai3/gptq-default')\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:13:41.477078Z",
          "iopub.status.busy": "2025-04-29T19:13:41.476885Z",
          "iopub.status.idle": "2025-04-29T19:13:50.415641Z",
          "shell.execute_reply": "2025-04-29T19:13:50.414783Z",
          "shell.execute_reply.started": "2025-04-29T19:13:41.477061Z"
        },
        "id": "4U_QWwgFKl3l",
        "outputId": "720497a3-8ea8-41ff-b717-c5c444b4a2a6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPTQ library from: /kaggle/input/gptq-6/ModelCloud-GPTQModel-82c494f\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-29 19:13:47.485702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745954027.508864     443 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745954027.516080     443 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' for memory saving.      \n",
            "\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.                              \n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL: Augmented GPTQ Quantization (IDEAL Workflow - Recalculating qt)\n",
        "# ==============================================================================\n",
        "# !pip install -r /kaggle/input/gptqq-5/ModelCloud-GPTQModel-82c494f/requirements.txt\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import gc # Garbage collector\n",
        "from functools import partial\n",
        "import logging # Import Python's logging\n",
        "GPTQ_LIB_PATH = '/kaggle/input/gptq-6/ModelCloud-GPTQModel-82c494f' # <--- CHANGE THIS if needed\n",
        "sys.path.append(GPTQ_LIB_PATH)\n",
        "print(f\"Using GPTQ library from: {GPTQ_LIB_PATH}\")\n",
        "\n",
        "from gptqmodel import GPTQModel, QuantizeConfig # Uses modified QuantizeConfig\n",
        "from gptqmodel.quantization.gptq import GPTQ   # Uses modified GPTQ class\n",
        "from gptqmodel.utils.model import find_modules\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "import torch.nn as nn\n",
        "import transformers as tf\n",
        "import tqdm\n",
        "from packaging import version\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:13:50.417362Z",
          "iopub.status.busy": "2025-04-29T19:13:50.416827Z",
          "iopub.status.idle": "2025-04-29T19:13:50.42416Z",
          "shell.execute_reply": "2025-04-29T19:13:50.423294Z",
          "shell.execute_reply.started": "2025-04-29T19:13:50.417342Z"
        },
        "id": "rilormRqKl3m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def find_layers(module, layers=[nn.Linear, tf.pytorch_utils.Conv1D], name=''):\n",
        "    if type(module) in layers:\n",
        "        if hasattr(module, 'weight'): return {name: module}\n",
        "        else: return {}\n",
        "    res={};\n",
        "    for cn, cm in module.named_children(): fn = name + '.' + cn if name else cn; res.update(find_layers(cm, layers=layers, name=fn))\n",
        "    return res\n",
        "\n",
        "def process_vision_info(messages):\n",
        "    images = []; videos = []\n",
        "    for msg in messages:\n",
        "        if msg.get('role') == 'user' and isinstance(msg.get('content'), list):\n",
        "            for item in msg['content']:\n",
        "                if item.get('type') == 'image' and 'image' in item: images.append(item['image'])\n",
        "    return images, videos\n",
        "\n",
        "log = logging.getLogger(\"AugmentedGPTQ_Ideal\") \n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "model_id = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
        "quant_path = \"/kaggle/working/Qwen_Augmented_Ideal_v1\" \n",
        "access_token = \"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\" \n",
        "\n",
        "quant_config = QuantizeConfig(\n",
        "    bits=8, group_size=128, beta=0.05, gamma=0.0, tau=1.0\n",
        ")\n",
        "log.info(f\"Quantization Config: {quant_config}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:13:50.425413Z",
          "iopub.status.busy": "2025-04-29T19:13:50.424884Z",
          "iopub.status.idle": "2025-04-29T19:13:50.443146Z",
          "shell.execute_reply": "2025-04-29T19:13:50.442363Z",
          "shell.execute_reply.started": "2025-04-29T19:13:50.42539Z"
        },
        "id": "6piLhnFUKl3m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "VOC_ROOT = './voc_data_calib_aug_ideal'\n",
        "VOC_YEAR = '2007'; VOC_IMAGE_SET = 'trainval'; DOWNLOAD_VOC = True\n",
        "NUM_CALIBRATION_SAMPLES = 3\n",
        "CALIBRATION_BATCH_SIZE = 1   \n",
        "logit_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "try:\n",
        "    from gptqmodel.quantization.gptq import DEVICE_1 as HESSIAN_DEVICE\n",
        "except ImportError: HESSIAN_DEVICE = logit_device\n",
        "log.info(f\"Device for Forward Passes: {logit_device}\")\n",
        "log.info(f\"Device for Hessian Computations: {HESSIAN_DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:13:50.445029Z",
          "iopub.status.busy": "2025-04-29T19:13:50.444809Z",
          "iopub.status.idle": "2025-04-29T19:13:55.958171Z",
          "shell.execute_reply": "2025-04-29T19:13:55.957321Z",
          "shell.execute_reply.started": "2025-04-29T19:13:50.445013Z"
        },
        "id": "GLFdxgczKl3n",
        "outputId": "b2f9969c-71f8-42c8-8bc6-c9e3af2c78de",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./voc_data_calib_aug_ideal/VOCtrainval_06-Nov-2007.tar\n",
            "Extracting ./voc_data_calib_aug_ideal/VOCtrainval_06-Nov-2007.tar to ./voc_data_calib_aug_ideal\n"
          ]
        }
      ],
      "source": [
        "log.info(\"Loading and preparing calibration data...\")\n",
        "try:\n",
        "    voc_dataset = datasets.VOCDetection(root=VOC_ROOT, year=VOC_YEAR, image_set=VOC_IMAGE_SET, download=DOWNLOAD_VOC)\n",
        "    log.info(f\"VOC dataset loaded ({len(voc_dataset)} images).\")\n",
        "    calibration_data = []\n",
        "    sample_indices = range(min(NUM_CALIBRATION_SAMPLES, len(voc_dataset)))\n",
        "    for i in sample_indices:\n",
        "        try:\n",
        "            img, target = voc_dataset[i];\n",
        "            if img is None: continue\n",
        "            boxes_info = target.get('annotation', {}).get('object', []);\n",
        "            if not isinstance(boxes_info, list): boxes_info = [boxes_info]\n",
        "            image_class_names = list(set([b['name'] for b in boxes_info if 'name' in b]))\n",
        "            if not image_class_names: continue\n",
        "            user_text_query = f\"Describe the objects: {', '.join(image_class_names)}.\"\n",
        "            calibration_data.append({'image': img, 'text': user_text_query})\n",
        "        except Exception as e: log.warning(f\"Skipping VOC sample {i} due to error: {e}\")\n",
        "    if not calibration_data: raise ValueError(\"No calibration data prepared.\")\n",
        "    NUM_CALIBRATION_SAMPLES = len(calibration_data)\n",
        "    num_batches = (NUM_CALIBRATION_SAMPLES + CALIBRATION_BATCH_SIZE - 1) // CALIBRATION_BATCH_SIZE\n",
        "    log.info(f\"Prepared {NUM_CALIBRATION_SAMPLES} calibration examples. Num batches: {num_batches}\")\n",
        "except Exception as e: log.error(f\"Error loading/processing calibration data: {e}\", exc_info=True); raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4237324e9cea4163913e0d378b344f51",
            "60a19b985c8c429fa9513506b8319db6"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-04-29T19:13:55.959869Z",
          "iopub.status.busy": "2025-04-29T19:13:55.959225Z",
          "iopub.status.idle": "2025-04-29T19:14:02.426985Z",
          "shell.execute_reply": "2025-04-29T19:14:02.426417Z",
          "shell.execute_reply.started": "2025-04-29T19:13:55.959844Z"
        },
        "id": "KENrXTv4Kl3n",
        "outputId": "da71c37f-cdc8-40c7-bb82-fdddb3eaf9a4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Estimated Quantization BPW (bits per weight): 8.31875 bpw, based on [bits: 8, group_size: 128]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4237324e9cea4163913e0d378b344f51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60a19b985c8c429fa9513506b8319db6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Model: Loaded `generation_config`: GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.05,\n",
            "  \"temperature\": 1e-06\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Kernel: loaded -> `[]`                                                                       \n"
          ]
        }
      ],
      "source": [
        "log.info(\"Loading Model and Processor...\")\n",
        "model_gptq = None; processor = None\n",
        "try:\n",
        "    compute_dtype = torch.float16\n",
        "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported(): compute_dtype = torch.bfloat16\n",
        "    log.info(f\"Using compute dtype: {compute_dtype}\")\n",
        "    model_gptq = GPTQModel.load(model_id, quant_config, trust_remote_code=True,\n",
        "                               token=access_token, torch_dtype=compute_dtype, device_map=\"auto\")\n",
        "    model_gptq.model.eval()\n",
        "    log.info(f\"Model loaded. Device map:\\n{getattr(model_gptq.model, 'hf_device_map', 'N/A')}\")\n",
        "    processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True, token=access_token)\n",
        "    tokenizer = processor.tokenizer\n",
        "    log.info(\"Processor loaded.\")\n",
        "except Exception as e:\n",
        "    log.error(f\"Error loading model or processor: {e}\", exc_info=True)\n",
        "    del model_gptq; gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None; raise\n",
        "log.info(\"Identifying layers and preparing GPTQ instances...\")\n",
        "SUPPORTED_LAYERS_FOR_FINDING = [nn.Linear]\n",
        "if hasattr(tf.pytorch_utils, 'Conv1D'):\n",
        "    SUPPORTED_LAYERS_FOR_FINDING.append(tf.pytorch_utils.Conv1D)\n",
        "else:\n",
        "    log.warning(\"transformers.pytorch_utils.Conv1D not found, only finding nn.Linear.\")\n",
        "\n",
        "layers_to_quantize = find_modules(model_gptq.model, layers=SUPPORTED_LAYERS_FOR_FINDING)\n",
        "log.info(f\"Found {len(layers_to_quantize)} layers: {list(layers_to_quantize.keys())[:5]}...\")\n",
        "def get_gptq_instance(layer_module):\n",
        "    if hasattr(layer_module, 'gptq_instance') and isinstance(layer_module.gptq_instance, GPTQ): return layer_module.gptq_instance\n",
        "    else: gptq_instance = GPTQ(layer_module, quant_config); layer_module.gptq_instance = gptq_instance; return gptq_instance\n",
        "for name, module in layers_to_quantize.items(): _ = get_gptq_instance(module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:14:02.428154Z",
          "iopub.status.busy": "2025-04-29T19:14:02.427925Z",
          "iopub.status.idle": "2025-04-29T19:17:32.526717Z",
          "shell.execute_reply": "2025-04-29T19:17:32.526101Z",
          "shell.execute_reply.started": "2025-04-29T19:14:02.428135Z"
        },
        "id": "fhOtF70cKl3o",
        "outputId": "96e2978f-086a-4088-feb5-2c7fcd8523cd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pass 1 Batches: 100%|██████████| 3/3 [03:29<00:00, 69.91s/it]\n"
          ]
        }
      ],
      "source": [
        "log.info(\"Starting Calibration Pass 1: Caching Teacher outputs (pt) and layer inputs (xt)...\")\n",
        "cached_layer_inputs = {name: [] for name in layers_to_quantize}\n",
        "cached_teacher_probs = [] \n",
        "layer_inputs_this_batch = {name: [] for name in layers_to_quantize}\n",
        "hooks = []\n",
        "def capture_input_hook(module, args, kwargs, layer_name):\n",
        "    inp = None\n",
        "    if args: inp = args[0]\n",
        "    elif kwargs.get('hidden_states'): inp = kwargs['hidden_states']\n",
        "    if inp is not None and isinstance(inp, torch.Tensor):\n",
        "        layer_inputs_this_batch[layer_name].append(inp.detach().cpu())\n",
        "\n",
        "log.info(\"Registering forward hooks...\")\n",
        "for name, module in layers_to_quantize.items():\n",
        "    hook_fn = partial(capture_input_hook, layer_name=name)\n",
        "    hooks.append(module.register_forward_hook(hook_fn))\n",
        "if torch.cuda.is_available():\n",
        "     try: compute_device = next(model_gptq.model.parameters()).device\n",
        "     except StopIteration: compute_device = logit_device\n",
        "else: compute_device = torch.device(\"cpu\")\n",
        "log.info(f\"Using device for Pass 1 forward: {compute_device}\")\n",
        "\n",
        "for i in tqdm.tqdm(range(num_batches), desc=\"Pass 1 Batches\"):\n",
        "    batch_data_raw = calibration_data[i*CALIBRATION_BATCH_SIZE:(i+1)*CALIBRATION_BATCH_SIZE]\n",
        "    if not batch_data_raw: continue\n",
        "    batch_texts_for_processor = []; batch_images_for_processor = []\n",
        "    valid_samples_in_batch = True\n",
        "    for item in batch_data_raw:\n",
        "        messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": item['image']}, {\"type\": \"text\", \"text\": item['text']}]}]\n",
        "        try:\n",
        "            formatted_text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "            images_extracted, _ = process_vision_info(messages)\n",
        "            batch_texts_for_processor.append(formatted_text); batch_images_for_processor.extend(images_extracted)\n",
        "        except Exception as e: log.warning(f\"Error formatting sample in batch {i}: {e}.\"); valid_samples_in_batch=False; break\n",
        "    if not valid_samples_in_batch or not batch_texts_for_processor:\n",
        "        log.warning(f\"Skipping batch {i} due to formatting errors.\"); cached_teacher_probs.append(None)\n",
        "        for name in layers_to_quantize: cached_layer_inputs[name].append(None); continue\n",
        "    try:\n",
        "        inputs = processor(text=batch_texts_for_processor, images=batch_images_for_processor, padding=True, return_tensors=\"pt\").to(compute_device, dtype=compute_dtype)\n",
        "    except Exception as e:\n",
        "        log.error(f\"Error processing batch {i}: {e}. Skipping.\", exc_info=True)\n",
        "        cached_teacher_probs.append(None)\n",
        "        for name in layers_to_quantize: cached_layer_inputs[name].append(None) \n",
        "        continue \n",
        "    for name in layers_to_quantize: layer_inputs_this_batch[name] = []\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            outputs = model_gptq.model(**inputs)\n",
        "            pt = torch.softmax(outputs.logits / quant_config.tau, dim=-1)\n",
        "            cached_teacher_probs.append(pt.detach().cpu()) \n",
        "            del outputs, pt\n",
        "    except Exception as e:\n",
        "        log.error(f\"Error Pass 1 Forward, batch {i}: {e}. Skipping.\", exc_info=True)\n",
        "        cached_teacher_probs.append(None)\n",
        "        for name in layers_to_quantize: cached_layer_inputs[name].append(layer_inputs_this_batch[name][-1] if layer_inputs_this_batch[name] else None)\n",
        "        continue\n",
        "    for name in layers_to_quantize: cached_layer_inputs[name].append(layer_inputs_this_batch[name][-1] if layer_inputs_this_batch[name] else None)\n",
        "\n",
        "log.info(\"Removing forward hooks.\"); [h.remove() for h in hooks]; hooks.clear(); del layer_inputs_this_batch\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "log.info(\"Finished Calibration Pass 1.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-04-29T19:17:32.527962Z",
          "iopub.status.busy": "2025-04-29T19:17:32.52767Z",
          "iopub.status.idle": "2025-04-29T19:43:56.785173Z",
          "shell.execute_reply": "2025-04-29T19:43:56.784539Z",
          "shell.execute_reply.started": "2025-04-29T19:17:32.527935Z"
        },
        "id": "-oG7GmEEKl3o",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e2e8ce2b-035a-458a-b523-7b570a907280",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Prep Pass 2 Inputs: 100%|██████████| 3/3 [00:00<00:00, 63.02it/s]\n",
            "Quantizing Layers:   0%|          | 0/415 [00:00<?, ?it/s]\n",
            "      Update qt (Layer 0):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "      Update qt (Layer 0):  33%|███▎      | 1/3 [00:59<01:58, 59.41s/it]\u001b[A\n",
            "      Update qt (Layer 0):  67%|██████▋   | 2/3 [01:54<00:56, 56.88s/it]\u001b[A\n",
            "      Update qt (Layer 0): 100%|██████████| 3/3 [02:54<00:00, 58.36s/it]\u001b[A\n",
            "                                                                        \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   0%|          | 1/415 [02:57<20:23:53, 177.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   0%|          | 2/415 [02:58<8:26:28, 73.58s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.50s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   1%|          | 3/415 [02:59<4:37:35, 40.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   1%|          | 4/415 [03:00<2:50:08, 24.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.23s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   1%|          | 5/415 [03:01<1:52:49, 16.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   1%|▏         | 6/415 [03:02<1:16:26, 11.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   2%|▏         | 7/415 [03:03<53:21,  7.85s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   2%|▏         | 8/415 [03:04<38:17,  5.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   2%|▏         | 9/415 [03:05<28:13,  4.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   2%|▏         | 10/415 [03:07<22:57,  3.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   3%|▎         | 11/415 [03:08<17:49,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   3%|▎         | 12/415 [03:09<14:14,  2.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.52s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   3%|▎         | 13/415 [03:10<11:56,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   3%|▎         | 14/415 [03:11<10:13,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.22s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   4%|▎         | 15/415 [03:12<10:34,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   4%|▍         | 16/415 [03:13<09:15,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   4%|▍         | 17/415 [03:14<08:18,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   4%|▍         | 18/415 [03:15<07:40,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   5%|▍         | 19/415 [03:16<07:12,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.20s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   5%|▍         | 20/415 [03:18<08:20,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   5%|▌         | 21/415 [03:19<07:41,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   5%|▌         | 22/415 [03:20<07:12,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   6%|▌         | 23/415 [03:21<06:51,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   6%|▌         | 24/415 [03:22<06:37,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   6%|▌         | 25/415 [03:23<07:51,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   6%|▋         | 26/415 [03:24<07:14,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.43s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   7%|▋         | 27/415 [03:25<06:46,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   7%|▋         | 28/415 [03:26<06:28,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   7%|▋         | 29/415 [03:27<06:15,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   7%|▋         | 30/415 [03:28<07:31,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   7%|▋         | 31/415 [03:29<06:59,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   8%|▊         | 32/415 [03:30<06:34,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   8%|▊         | 33/415 [03:31<06:20,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   8%|▊         | 34/415 [03:32<06:09,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   8%|▊         | 35/415 [03:34<07:24,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   9%|▊         | 36/415 [03:35<06:53,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.43s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   9%|▉         | 37/415 [03:35<06:27,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   9%|▉         | 38/415 [03:36<06:15,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:   9%|▉         | 39/415 [03:37<06:11,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.24s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  10%|▉         | 40/415 [03:39<07:32,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  10%|▉         | 41/415 [03:40<07:01,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  10%|█         | 42/415 [03:41<06:42,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.51s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  10%|█         | 43/415 [03:42<06:30,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  11%|█         | 44/415 [03:43<06:15,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.19s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  11%|█         | 45/415 [03:45<07:27,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  11%|█         | 46/415 [03:45<06:54,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  11%|█▏        | 47/415 [03:46<06:28,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  12%|█▏        | 48/415 [03:47<06:11,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  12%|█▏        | 49/415 [03:48<06:00,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.26s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  12%|█▏        | 50/415 [03:50<07:24,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  12%|█▏        | 51/415 [03:51<07:01,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  13%|█▎        | 52/415 [03:52<06:39,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  13%|█▎        | 53/415 [03:53<06:22,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  13%|█▎        | 54/415 [03:54<06:09,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.20s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  13%|█▎        | 55/415 [03:56<07:18,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  13%|█▎        | 56/415 [03:56<06:47,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  14%|█▎        | 57/415 [03:57<06:27,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  14%|█▍        | 58/415 [03:58<06:14,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  14%|█▍        | 59/415 [03:59<06:05,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.25s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  14%|█▍        | 60/415 [04:01<07:22,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  15%|█▍        | 61/415 [04:02<06:51,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  15%|█▍        | 62/415 [04:03<06:27,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.50s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  15%|█▌        | 63/415 [04:04<06:16,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  15%|█▌        | 64/415 [04:05<06:02,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  16%|█▌        | 65/415 [04:07<07:08,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  16%|█▌        | 66/415 [04:08<06:35,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  16%|█▌        | 67/415 [04:08<06:08,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  16%|█▋        | 68/415 [04:09<05:51,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000013, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  17%|█▋        | 69/415 [04:10<05:39,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.22s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  17%|█▋        | 70/415 [04:12<06:56,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  17%|█▋        | 71/415 [04:13<06:29,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  17%|█▋        | 72/415 [04:14<06:05,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  18%|█▊        | 73/415 [04:15<05:48,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  18%|█▊        | 74/415 [04:16<05:36,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.20s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  18%|█▊        | 75/415 [04:17<06:46,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  18%|█▊        | 76/415 [04:18<06:22,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  19%|█▊        | 77/415 [04:19<06:04,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  19%|█▉        | 78/415 [04:20<05:48,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000019, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  19%|█▉        | 79/415 [04:21<05:39,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.258344, Time=1.20s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  19%|█▉        | 80/415 [04:23<06:47,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.51s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  20%|█▉        | 81/415 [04:24<06:25,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  20%|█▉        | 82/415 [04:25<06:04,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  20%|██        | 83/415 [04:26<05:50,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  20%|██        | 84/415 [04:27<05:41,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=1.25s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  20%|██        | 85/415 [04:29<06:51,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.50s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  21%|██        | 86/415 [04:30<06:25,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  21%|██        | 87/415 [04:31<06:02,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000095, Time=0.53s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  21%|██        | 88/415 [04:32<05:54,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000329, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  21%|██▏       | 89/415 [04:33<05:42,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=15063525645.684484, Time=1.25s, Damp Used=0.01000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  22%|██▏       | 90/415 [04:34<06:49,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  22%|██▏       | 91/415 [04:35<06:17,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  22%|██▏       | 92/415 [04:36<05:54,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  22%|██▏       | 93/415 [04:37<05:41,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  23%|██▎       | 94/415 [04:38<05:31,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.23s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  23%|██▎       | 95/415 [04:40<06:36,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  23%|██▎       | 96/415 [04:41<06:08,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  23%|██▎       | 97/415 [04:42<05:49,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  24%|██▎       | 98/415 [04:43<05:36,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.51s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  24%|██▍       | 99/415 [04:44<05:31,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.27s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  24%|██▍       | 100/415 [04:46<06:38,  1.27s/it]\n",
            "      Update qt (Layer 100):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "      Update qt (Layer 100):  33%|███▎      | 1/3 [01:05<02:11, 65.73s/it]\u001b[A\n",
            "      Update qt (Layer 100):  67%|██████▋   | 2/3 [02:04<01:01, 61.38s/it]\u001b[A\n",
            "      Update qt (Layer 100): 100%|██████████| 3/3 [03:07<00:00, 62.39s/it]\u001b[A\n",
            "                                                                          \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  24%|██▍       | 101/415 [07:55<5:01:23, 57.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  25%|██▍       | 102/415 [07:55<3:31:47, 40.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  25%|██▍       | 103/415 [07:56<2:29:17, 28.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  25%|██▌       | 104/415 [07:57<1:45:40, 20.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=1.28s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  25%|██▌       | 105/415 [07:59<1:16:29, 14.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.48s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  26%|██▌       | 106/415 [08:00<54:51, 10.65s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  26%|██▌       | 107/415 [08:01<39:44,  7.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  26%|██▌       | 108/415 [08:02<29:11,  5.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  26%|██▋       | 109/415 [08:03<21:47,  4.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  27%|██▋       | 110/415 [08:05<17:45,  3.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  27%|██▋       | 111/415 [08:06<13:49,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  27%|██▋       | 112/415 [08:07<11:01,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  27%|██▋       | 113/415 [08:07<09:04,  1.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  27%|██▋       | 114/415 [08:08<07:43,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.21s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  28%|██▊       | 115/415 [08:10<07:55,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000009, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  28%|██▊       | 116/415 [08:11<06:53,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  28%|██▊       | 117/415 [08:12<06:10,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  28%|██▊       | 118/415 [08:13<05:42,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  29%|██▊       | 119/415 [08:14<05:21,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.20s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  29%|██▉       | 120/415 [08:15<06:12,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  29%|██▉       | 121/415 [08:16<05:40,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  29%|██▉       | 122/415 [08:17<05:18,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  30%|██▉       | 123/415 [08:18<05:04,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  30%|██▉       | 124/415 [08:19<04:53,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  30%|███       | 125/415 [08:21<05:49,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.49s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  30%|███       | 126/415 [08:22<05:26,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  31%|███       | 127/415 [08:23<05:07,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  31%|███       | 128/415 [08:24<04:52,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  31%|███       | 129/415 [08:24<04:42,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  31%|███▏      | 130/415 [08:26<05:39,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  32%|███▏      | 131/415 [08:27<05:16,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  32%|███▏      | 132/415 [08:28<04:58,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  32%|███▏      | 133/415 [08:29<04:46,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=0.51s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  32%|███▏      | 134/415 [08:30<04:44,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=1.24s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  33%|███▎      | 135/415 [08:32<05:42,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  33%|███▎      | 136/415 [08:33<05:15,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  33%|███▎      | 137/415 [08:33<04:56,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  33%|███▎      | 138/415 [08:34<04:42,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000010, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  33%|███▎      | 139/415 [08:35<04:33,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=1.19s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  34%|███▎      | 140/415 [08:37<05:28,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  34%|███▍      | 141/415 [08:38<05:05,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.43s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  34%|███▍      | 142/415 [08:39<04:47,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000009, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  34%|███▍      | 143/415 [08:40<04:34,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000013, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  35%|███▍      | 144/415 [08:41<04:26,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000009, Time=1.23s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  35%|███▍      | 145/415 [08:42<05:24,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.47s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  35%|███▌      | 146/415 [08:43<05:01,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  35%|███▌      | 147/415 [08:44<04:42,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000013, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  36%|███▌      | 148/415 [08:45<04:30,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000013, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  36%|███▌      | 149/415 [08:46<04:22,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000015, Time=1.18s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  36%|███▌      | 150/415 [08:48<05:15,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000010, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  36%|███▋      | 151/415 [08:49<04:52,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=0.44s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  37%|███▋      | 152/415 [08:50<04:36,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000011, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  37%|███▋      | 153/415 [08:50<04:24,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000012, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  37%|███▋      | 154/415 [08:51<04:19,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000029, Time=1.21s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  37%|███▋      | 155/415 [08:53<05:12,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000033, Time=0.46s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  38%|███▊      | 156/415 [08:54<04:50,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000075, Time=0.43s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  38%|███▊      | 157/415 [08:55<04:32,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000016, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  38%|███▊      | 158/415 [08:56<04:20,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([1280, 1280])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/1280                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1152-1279/1280                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000016, Time=0.45s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  38%|███▊      | 159/415 [08:57<04:12,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([3420, 3420])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/3420                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3328-3419/3420                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=1725986758576482560.000000, Time=1.18s, Damp Used=0.01000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  39%|███▊      | 160/415 [08:58<05:02,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 684 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([5120, 5120])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/5120                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 4992-5119/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=2.23s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  39%|███▉      | 161/415 [09:01<06:57,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 684 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([5120, 5120])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/5120                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 4992-5119/5120                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=1.99s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  39%|███▉      | 162/415 [09:04<08:01,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000013, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  39%|███▉      | 163/415 [09:05<07:08,  1.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  40%|███▉      | 164/415 [09:06<06:28,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  40%|███▉      | 165/415 [09:07<05:59,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  40%|████      | 166/415 [09:08<05:39,  1.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000010, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  40%|████      | 167/415 [09:10<05:38,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  40%|████      | 168/415 [09:11<05:38,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=5.32s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  41%|████      | 169/415 [09:17<11:11,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  41%|████      | 170/415 [09:18<09:23,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  41%|████      | 171/415 [09:20<07:59,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  41%|████▏     | 172/415 [09:21<07:01,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.76s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  42%|████▏     | 173/415 [09:22<06:25,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.002997, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  42%|████▏     | 174/415 [09:23<06:07,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.005482, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  42%|████▏     | 175/415 [09:25<05:55,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=5.13s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  42%|████▏     | 176/415 [09:30<10:55,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.79s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  43%|████▎     | 177/415 [09:32<09:14,  2.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.78s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  43%|████▎     | 178/415 [09:33<07:56,  2.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  43%|████▎     | 179/415 [09:34<06:56,  1.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  43%|████▎     | 180/415 [09:36<06:17,  1.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000495, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  44%|████▎     | 181/415 [09:37<06:00,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.001117, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  44%|████▍     | 182/415 [09:38<05:49,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.693784, Time=5.09s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  44%|████▍     | 183/415 [09:44<10:37,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  44%|████▍     | 184/415 [09:45<08:53,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  45%|████▍     | 185/415 [09:46<07:33,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  45%|████▍     | 186/415 [09:48<06:37,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  45%|████▌     | 187/415 [09:49<06:00,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000309, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  45%|████▌     | 188/415 [09:50<05:45,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000746, Time=0.92s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  46%|████▌     | 189/415 [09:52<05:36,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.16s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  46%|████▌     | 190/415 [09:57<10:21,  2.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  46%|████▌     | 191/415 [09:59<08:39,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  46%|████▋     | 192/415 [10:00<07:21,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  47%|████▋     | 193/415 [10:01<06:26,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  47%|████▋     | 194/415 [10:02<05:49,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000268, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  47%|████▋     | 195/415 [10:04<05:35,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000327, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  47%|████▋     | 196/415 [10:05<05:23,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=5.06s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  47%|████▋     | 197/415 [10:11<09:52,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.76s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  48%|████▊     | 198/415 [10:12<08:18,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  48%|████▊     | 199/415 [10:13<07:02,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  48%|████▊     | 200/415 [10:14<06:08,  1.71s/it]\n",
            "      Update qt (Layer 200):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "      Update qt (Layer 200):  33%|███▎      | 1/3 [01:02<02:05, 62.54s/it]\u001b[A\n",
            "      Update qt (Layer 200):  67%|██████▋   | 2/3 [02:01<01:00, 60.67s/it]\u001b[A\n",
            "      Update qt (Layer 200): 100%|██████████| 3/3 [03:08<00:00, 63.46s/it]\u001b[A\n",
            "                                                                          \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.75s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  48%|████▊     | 201/415 [13:25<3:27:51, 58.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000358, Time=0.92s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  49%|████▊     | 202/415 [13:26<2:26:20, 41.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000665, Time=0.92s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  49%|████▉     | 203/415 [13:27<1:43:27, 29.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=5.14s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  49%|████▉     | 204/415 [13:33<1:18:06, 22.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  49%|████▉     | 205/415 [13:34<55:45, 15.93s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  50%|████▉     | 206/415 [13:36<40:04, 11.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  50%|████▉     | 207/415 [13:37<29:08,  8.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  50%|█████     | 208/415 [13:38<21:32,  6.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000409, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  50%|█████     | 209/415 [13:39<16:25,  4.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000838, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  51%|█████     | 210/415 [13:41<12:49,  3.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=5.15s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  51%|█████     | 211/415 [13:46<14:46,  4.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000012, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  51%|█████     | 212/415 [13:48<11:36,  3.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  51%|█████▏    | 213/415 [13:49<09:18,  2.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.79s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  52%|█████▏    | 214/415 [13:50<07:47,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.76s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  52%|█████▏    | 215/415 [13:51<06:41,  2.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000408, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  52%|█████▏    | 216/415 [13:53<06:01,  1.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.001144, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  52%|█████▏    | 217/415 [13:54<05:33,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=5.16s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  53%|█████▎    | 218/415 [14:00<09:30,  2.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  53%|█████▎    | 219/415 [14:01<07:54,  2.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  53%|█████▎    | 220/415 [14:02<06:39,  2.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  53%|█████▎    | 221/415 [14:04<05:45,  1.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  53%|█████▎    | 222/415 [14:05<05:10,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000331, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  54%|█████▎    | 223/415 [14:06<04:53,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000441, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  54%|█████▍    | 224/415 [14:07<04:42,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=5.21s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  54%|█████▍    | 225/415 [14:13<08:45,  2.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  54%|█████▍    | 226/415 [14:15<07:19,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  55%|█████▍    | 227/415 [14:16<06:11,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  55%|█████▍    | 228/415 [14:17<05:25,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  55%|█████▌    | 229/415 [14:18<04:53,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000179, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  55%|█████▌    | 230/415 [14:19<04:40,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000362, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  56%|█████▌    | 231/415 [14:21<04:30,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.17s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  56%|█████▌    | 232/415 [14:27<08:23,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  56%|█████▌    | 233/415 [14:28<07:00,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  56%|█████▋    | 234/415 [14:29<05:57,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  57%|█████▋    | 235/415 [14:30<05:13,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.75s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  57%|█████▋    | 236/415 [14:31<04:45,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000132, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  57%|█████▋    | 237/415 [14:33<04:31,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000401, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  57%|█████▋    | 238/415 [14:34<04:21,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.11s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  58%|█████▊    | 239/415 [14:40<08:01,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  58%|█████▊    | 240/415 [14:41<06:43,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  58%|█████▊    | 241/415 [14:42<05:42,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  58%|█████▊    | 242/415 [14:44<04:58,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  59%|█████▊    | 243/415 [14:45<04:28,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000076, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  59%|█████▉    | 244/415 [14:46<04:17,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000057, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  59%|█████▉    | 245/415 [14:47<04:08,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=5.24s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  59%|█████▉    | 246/415 [14:53<07:46,  2.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  60%|█████▉    | 247/415 [14:55<06:29,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  60%|█████▉    | 248/415 [14:56<05:30,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  60%|██████    | 249/415 [14:57<04:49,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  60%|██████    | 250/415 [14:58<04:21,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000083, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  60%|██████    | 251/415 [14:59<04:09,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000051, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  61%|██████    | 252/415 [15:01<04:00,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.12s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  61%|██████    | 253/415 [15:07<07:23,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  61%|██████    | 254/415 [15:08<06:10,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  61%|██████▏   | 255/415 [15:09<05:15,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  62%|██████▏   | 256/415 [15:10<04:35,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  62%|██████▏   | 257/415 [15:11<04:09,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000039, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  62%|██████▏   | 258/415 [15:13<03:58,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000028, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  62%|██████▏   | 259/415 [15:14<03:49,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.09s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  63%|██████▎   | 260/415 [15:20<07:02,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  63%|██████▎   | 261/415 [15:21<05:53,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  63%|██████▎   | 262/415 [15:22<04:59,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  63%|██████▎   | 263/415 [15:23<04:21,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.79s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  64%|██████▎   | 264/415 [15:25<03:59,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000042, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  64%|██████▍   | 265/415 [15:26<03:49,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000031, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  64%|██████▍   | 266/415 [15:27<03:39,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.21s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  64%|██████▍   | 267/415 [15:33<06:49,  2.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  65%|██████▍   | 268/415 [15:34<05:41,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  65%|██████▍   | 269/415 [15:36<04:48,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  65%|██████▌   | 270/415 [15:37<04:11,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  65%|██████▌   | 271/415 [15:38<03:47,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000036, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  66%|██████▌   | 272/415 [15:39<03:36,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000024, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  66%|██████▌   | 273/415 [15:41<03:28,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.11s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  66%|██████▌   | 274/415 [15:46<06:24,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  66%|██████▋   | 275/415 [15:48<05:21,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  67%|██████▋   | 276/415 [15:49<04:32,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  67%|██████▋   | 277/415 [15:50<03:58,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  67%|██████▋   | 278/415 [15:51<03:36,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000030, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  67%|██████▋   | 279/415 [15:53<03:26,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000023, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  67%|██████▋   | 280/415 [15:54<03:18,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.14s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  68%|██████▊   | 281/415 [16:00<06:07,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000009, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  68%|██████▊   | 282/415 [16:01<05:06,  2.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  68%|██████▊   | 283/415 [16:02<04:19,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  68%|██████▊   | 284/415 [16:03<03:45,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  69%|██████▊   | 285/415 [16:05<03:22,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000026, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  69%|██████▉   | 286/415 [16:06<03:14,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000024, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  69%|██████▉   | 287/415 [16:07<03:07,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.17s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  69%|██████▉   | 288/415 [16:13<05:48,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  70%|██████▉   | 289/415 [16:14<04:50,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  70%|██████▉   | 290/415 [16:16<04:05,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  70%|███████   | 291/415 [16:17<03:34,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  70%|███████   | 292/415 [16:18<03:12,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000029, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  71%|███████   | 293/415 [16:19<03:03,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000025, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  71%|███████   | 294/415 [16:21<02:56,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.09s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  71%|███████   | 295/415 [16:26<05:26,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000011, Time=0.82s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  71%|███████▏  | 296/415 [16:28<04:35,  2.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  72%|███████▏  | 297/415 [16:29<03:53,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  72%|███████▏  | 298/415 [16:30<03:22,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000009, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  72%|███████▏  | 299/415 [16:31<03:02,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000021, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  72%|███████▏  | 300/415 [16:33<02:53,  1.51s/it]\n",
            "      Update qt (Layer 300):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "      Update qt (Layer 300):  33%|███▎      | 1/3 [01:03<02:07, 63.86s/it]\u001b[A\n",
            "      Update qt (Layer 300):  67%|██████▋   | 2/3 [02:01<01:00, 60.38s/it]\u001b[A\n",
            "      Update qt (Layer 300): 100%|██████████| 3/3 [03:05<00:00, 62.09s/it]\u001b[A\n",
            "                                                                          \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000021, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  73%|███████▎  | 301/415 [19:40<1:48:57, 57.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.12s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  73%|███████▎  | 302/415 [19:46<1:18:49, 41.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000013, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  73%|███████▎  | 303/415 [19:47<55:23, 29.67s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  73%|███████▎  | 304/415 [19:48<39:03, 21.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  73%|███████▎  | 305/415 [19:49<27:43, 15.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  74%|███████▎  | 306/415 [19:51<19:52, 10.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000025, Time=0.92s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  74%|███████▍  | 307/415 [19:52<14:31,  8.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000028, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  74%|███████▍  | 308/415 [19:53<10:47,  6.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=5.15s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  74%|███████▍  | 309/415 [19:59<10:30,  5.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  75%|███████▍  | 310/415 [20:00<07:56,  4.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  75%|███████▍  | 311/415 [20:01<06:07,  3.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  75%|███████▌  | 312/415 [20:03<04:50,  2.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  75%|███████▌  | 313/415 [20:04<03:58,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000045, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  76%|███████▌  | 314/415 [20:05<03:25,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000024, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  76%|███████▌  | 315/415 [20:07<03:04,  1.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.19s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  76%|███████▌  | 316/415 [20:12<04:58,  3.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000016, Time=0.75s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  76%|███████▋  | 317/415 [20:14<04:05,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  77%|███████▋  | 318/415 [20:15<03:23,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  77%|███████▋  | 319/415 [20:16<02:53,  1.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  77%|███████▋  | 320/415 [20:17<02:34,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000027, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  77%|███████▋  | 321/415 [20:18<02:25,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000028, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  78%|███████▊  | 322/415 [20:20<02:18,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.14s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  78%|███████▊  | 323/415 [20:25<04:12,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000017, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  78%|███████▊  | 324/415 [20:27<03:29,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  78%|███████▊  | 325/415 [20:28<02:56,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  79%|███████▊  | 326/415 [20:29<02:34,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  79%|███████▉  | 327/415 [20:30<02:18,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000043, Time=0.94s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  79%|███████▉  | 328/415 [20:32<02:12,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000033, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  79%|███████▉  | 329/415 [20:33<02:05,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.08s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  80%|███████▉  | 330/415 [20:39<03:50,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  80%|███████▉  | 331/415 [20:40<03:11,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  80%|████████  | 332/415 [20:41<02:41,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  80%|████████  | 333/415 [20:42<02:19,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.75s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  80%|████████  | 334/415 [20:44<02:07,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000041, Time=0.90s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  81%|████████  | 335/415 [20:45<02:00,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000019, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  81%|████████  | 336/415 [20:46<01:55,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=5.14s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  81%|████████  | 337/415 [20:52<03:33,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  81%|████████▏ | 338/415 [20:53<02:56,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  82%|████████▏ | 339/415 [20:54<02:28,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  82%|████████▏ | 340/415 [20:56<02:08,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  82%|████████▏ | 341/415 [20:57<01:54,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000073, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  82%|████████▏ | 342/415 [20:58<01:48,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000033, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  83%|████████▎ | 343/415 [20:59<01:43,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.16s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  83%|████████▎ | 344/415 [21:05<03:13,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  83%|████████▎ | 345/415 [21:06<02:39,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  83%|████████▎ | 346/415 [21:07<02:14,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  84%|████████▎ | 347/415 [21:09<01:56,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  84%|████████▍ | 348/415 [21:10<01:44,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000055, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  84%|████████▍ | 349/415 [21:11<01:38,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000037, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  84%|████████▍ | 350/415 [21:13<01:34,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=5.14s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  85%|████████▍ | 351/415 [21:18<02:54,  2.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000031, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  85%|████████▍ | 352/415 [21:19<02:23,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  85%|████████▌ | 353/415 [21:21<02:00,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  85%|████████▌ | 354/415 [21:22<01:44,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000010, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  86%|████████▌ | 355/415 [21:23<01:33,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000093, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  86%|████████▌ | 356/415 [21:24<01:27,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000044, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  86%|████████▌ | 357/415 [21:26<01:23,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=5.07s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  86%|████████▋ | 358/415 [21:31<02:34,  2.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  87%|████████▋ | 359/415 [21:33<02:07,  2.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  87%|████████▋ | 360/415 [21:34<01:46,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  87%|████████▋ | 361/415 [21:35<01:32,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  87%|████████▋ | 362/415 [21:36<01:22,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000084, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  87%|████████▋ | 363/415 [21:37<01:17,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000059, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  88%|████████▊ | 364/415 [21:39<01:14,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=5.16s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  88%|████████▊ | 365/415 [21:45<02:16,  2.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000004, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  88%|████████▊ | 366/415 [21:46<01:52,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.76s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  88%|████████▊ | 367/415 [21:47<01:35,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000000, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  89%|████████▊ | 368/415 [21:48<01:22,  1.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.75s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  89%|████████▉ | 369/415 [21:49<01:13,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000077, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  89%|████████▉ | 370/415 [21:51<01:08,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000096, Time=0.92s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  89%|████████▉ | 371/415 [21:52<01:04,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=5.11s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  90%|████████▉ | 372/415 [21:58<01:57,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000010, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  90%|████████▉ | 373/415 [21:59<01:36,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  90%|█████████ | 374/415 [22:00<01:20,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  90%|█████████ | 375/415 [22:02<01:08,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  91%|█████████ | 376/415 [22:03<01:00,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000105, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  91%|█████████ | 377/415 [22:04<00:56,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000131, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  91%|█████████ | 378/415 [22:05<00:53,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000723, Time=5.15s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  91%|█████████▏| 379/415 [22:11<01:38,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000014, Time=0.76s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  92%|█████████▏| 380/415 [22:12<01:20,  2.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  92%|█████████▏| 381/415 [22:14<01:06,  1.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  92%|█████████▏| 382/415 [22:15<00:56,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000021, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  92%|█████████▏| 383/415 [22:16<00:49,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000092, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  93%|█████████▎| 384/415 [22:17<00:46,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000121, Time=0.96s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  93%|█████████▎| 385/415 [22:19<00:44,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000021, Time=5.12s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  93%|█████████▎| 386/415 [22:24<01:19,  2.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000022, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  93%|█████████▎| 387/415 [22:26<01:04,  2.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000003, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  93%|█████████▎| 388/415 [22:27<00:52,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  94%|█████████▎| 389/415 [22:28<00:44,  1.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  94%|█████████▍| 390/415 [22:29<00:38,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000111, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  94%|█████████▍| 391/415 [22:30<00:35,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000075, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  94%|█████████▍| 392/415 [22:32<00:33,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000022, Time=5.10s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  95%|█████████▍| 393/415 [22:37<00:59,  2.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000030, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  95%|█████████▍| 394/415 [22:39<00:47,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000002, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  95%|█████████▌| 395/415 [22:40<00:38,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000011, Time=0.69s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  95%|█████████▌| 396/415 [22:41<00:32,  1.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  96%|█████████▌| 397/415 [22:42<00:28,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000086, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  96%|█████████▌| 398/415 [22:44<00:25,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000128, Time=0.89s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  96%|█████████▌| 399/415 [22:45<00:23,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000038, Time=5.12s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  96%|█████████▋| 400/415 [22:51<00:40,  2.72s/it]\n",
            "      Update qt (Layer 400):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "      Update qt (Layer 400):  33%|███▎      | 1/3 [01:00<02:01, 60.97s/it]\u001b[A\n",
            "      Update qt (Layer 400):  67%|██████▋   | 2/3 [01:57<00:58, 58.50s/it]\u001b[A\n",
            "      Update qt (Layer 400): 100%|██████████| 3/3 [02:59<00:00, 60.12s/it]\u001b[A\n",
            "                                                                          \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000007, Time=0.75s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  97%|█████████▋| 401/415 [25:52<13:08, 56.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.71s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  97%|█████████▋| 402/415 [25:53<08:37, 39.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.70s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  97%|█████████▋| 403/415 [25:54<05:38, 28.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000008, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  97%|█████████▋| 404/415 [25:56<03:41, 20.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000071, Time=0.88s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  98%|█████████▊| 405/415 [25:57<02:24, 14.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000107, Time=0.87s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  98%|█████████▊| 406/415 [25:58<01:34, 10.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000035, Time=5.19s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  98%|█████████▊| 407/415 [26:04<01:12,  9.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000005, Time=0.72s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  98%|█████████▊| 408/415 [26:05<00:47,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  99%|█████████▊| 409/415 [26:06<00:30,  5.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000001, Time=0.73s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  99%|█████████▉| 410/415 [26:08<00:19,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000006, Time=0.74s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  99%|█████████▉| 411/415 [26:09<00:12,  3.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000276, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers:  99%|█████████▉| 412/415 [26:10<00:07,  2.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.000210, Time=0.91s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers: 100%|█████████▉| 413/415 [26:12<00:04,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([11008, 11008])) for layer hf_optimum...                  \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/11008                                              \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 2560-2687/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 3840-3967/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 5120-5247/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 6400-6527/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 7680-7807/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 8960-9087/11008                                          \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10240-10367/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 10880-11007/11008                                        \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.001784, Time=5.13s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers: 100%|█████████▉| 414/415 [26:17<00:03,  3.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Quantizing layer hf_optimum with 767 samples. beta=0.05, gamma=0.0                           \n",
            "\u001b[32mINFO\u001b[0m  Combined Hessian H_tot created for layer hf_optimum.                                         \n",
            "\u001b[32mINFO\u001b[0m  Applying activation order for layer hf_optimum based on H_tot.                               \n",
            "\u001b[32mINFO\u001b[0m  Inverting H_tot (shape: torch.Size([2048, 2048])) for layer hf_optimum...                    \n",
            "\u001b[32mINFO\u001b[0m  H_tot inverted using damp=0.01000 for layer hf_optimum.                                      \n",
            "\u001b[32mINFO\u001b[0m  Starting column loop for layer hf_optimum...                                                 \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 0-127/2048                                               \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1280-1407/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Processed columns 1920-2047/2048                                           \n",
            "\u001b[32mINFO\u001b[0m  Finished column loop for layer hf_optimum.                                                   \n",
            "\u001b[32mINFO\u001b[0m  Reverting activation order for layer hf_optimum.                                             \n",
            "\u001b[32mINFO\u001b[0m  Layer hf_optimum: Quantization finished. Avg Loss=0.008098, Time=5.87s, Damp Used=0.01000    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Quantizing Layers: 100%|██████████| 415/415 [26:24<00:00,  3.82s/it]\n"
          ]
        }
      ],
      "source": [
        "log.info(\"Starting Calibration Pass 2: Layer loop (Recalculating qt periodically)...\")\n",
        "layer_order = list(layers_to_quantize.keys())\n",
        "processed_layers_count = 0\n",
        "pass2_batch_inputs = []\n",
        "log.info(\"Preparing inputs for Pass 2 qt recalculations...\")\n",
        "for i in tqdm.tqdm(range(num_batches), desc=\"Prep Pass 2 Inputs\"):\n",
        "    batch_data_raw = calibration_data[i*CALIBRATION_BATCH_SIZE:(i+1)*CALIBRATION_BATCH_SIZE]\n",
        "    if not batch_data_raw: pass2_batch_inputs.append(None); continue\n",
        "    batch_texts = []; batch_images = []\n",
        "    valid = True\n",
        "    for item in batch_data_raw:\n",
        "        messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": item['image']}, {\"type\": \"text\", \"text\": item['text']}]}]\n",
        "        try:\n",
        "            formatted_text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "            images_extracted, _ = process_vision_info(messages)\n",
        "            batch_texts.append(formatted_text); batch_images.extend(images_extracted)\n",
        "        except: valid = False; break\n",
        "    if not valid or not batch_texts: pass2_batch_inputs.append(None); continue\n",
        "    try:\n",
        "        inputs_dict = processor(text=batch_texts, images=batch_images, padding=True, return_tensors=\"pt\")\n",
        "        pass2_batch_inputs.append({k: v.cpu() for k, v in inputs_dict.items()})\n",
        "    except Exception as e: log.error(f\"Error processing Pass 2 inputs batch {i}: {e}\"); pass2_batch_inputs.append(None)\n",
        "log.info(\"Finished preparing inputs for Pass 2.\")\n",
        "current_qt_cache_cpu = [None] * num_batches\n",
        "\n",
        "# --- Define update frequency ---\n",
        "QT_UPDATE_FREQUENCY = 100 \n",
        "log.info(f\"Will update qt cache every {QT_UPDATE_FREQUENCY} layers.\")\n",
        "\n",
        "# --- Start Layer Loop ---\n",
        "for layer_index, layer_name in enumerate(tqdm.tqdm(layer_order, desc=\"Quantizing Layers\")):\n",
        "    log.info(f\"--> Processing layer {layer_index + 1}/{len(layer_order)}: {layer_name}\")\n",
        "    layer_module = layers_to_quantize[layer_name]\n",
        "    gptq_instance = get_gptq_instance(layer_module)\n",
        "    gptq_instance.H_mse = None; gptq_instance.H_kl = None; gptq_instance.H_ce = None; gptq_instance.nsamples = 0\n",
        "    gptq_instance.quantizer = gptq_instance.create_quantizer(name=gptq_instance.name)\n",
        "    if layer_index % QT_UPDATE_FREQUENCY == 0:\n",
        "        log.info(f\"    Updating qt cache at layer index {layer_index}...\")\n",
        "        new_qt_cache_cpu = [None] * num_batches \n",
        "        for i in tqdm.tqdm(range(num_batches), desc=f\"      Update qt (Layer {layer_index})\", leave=False):\n",
        "            batch_proc_inputs = pass2_batch_inputs[i]\n",
        "            if batch_proc_inputs is None: continue\n",
        "            try:\n",
        "                current_inputs = {k: v.to(compute_device) for k, v in batch_proc_inputs.items()}\n",
        "                with torch.no_grad():\n",
        "                    qt_outputs = model_gptq.model(**current_inputs)\n",
        "                    qt_probs = torch.softmax(qt_outputs.logits / quant_config.tau, dim=-1)\n",
        "                    new_qt_cache_cpu[i] = qt_probs.detach().cpu()\n",
        "                del qt_outputs, qt_probs, current_inputs \n",
        "            except Exception as e:\n",
        "                log.error(f\"      Error updating qt for batch {i} at layer {layer_index}: {e}\", exc_info=True)\n",
        "                new_qt_cache_cpu[i] = None \n",
        "        current_qt_cache_cpu = new_qt_cache_cpu\n",
        "        log.info(f\"    qt cache updated for layers {layer_index} to {min(layer_index + QT_UPDATE_FREQUENCY - 1, len(layer_order)-1)}.\")\n",
        "        # Clear GPU cache after potentially large forward passes\n",
        "        gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "    # --- End qt update check ---\n",
        "\n",
        "    # --- Inner loop through cached batches to calculate Hessians ---\n",
        "    # log.info(f\"    Calculating Hessians for layer {layer_name} using potentially stale qt...\") # Reduce logging noise\n",
        "    layer_has_valid_batch = False\n",
        "    for i in range(num_batches):\n",
        "        inp_cpu = cached_layer_inputs[layer_name][i]\n",
        "        pt_cpu = cached_teacher_probs[i]\n",
        "        # --- Use the CURRENTLY CACHED (potentially stale) qt ---\n",
        "        qt_cpu = current_qt_cache_cpu[i]\n",
        "\n",
        "        # Skip if any required data is missing for this batch/layer\n",
        "        if inp_cpu is None or pt_cpu is None or qt_cpu is None: continue\n",
        "\n",
        "        try:\n",
        "            # Move needed tensors to Hessian device\n",
        "            inp_tensor = inp_cpu.to(HESSIAN_DEVICE)\n",
        "            pt_tensor = pt_cpu.to(HESSIAN_DEVICE)\n",
        "            qt_tensor = qt_cpu.to(HESSIAN_DEVICE) # Move the potentially stale qt\n",
        "            layer_has_valid_batch = True\n",
        "\n",
        "            # --- Alignment (Same as before) ---\n",
        "            inp_reshaped = inp_tensor.reshape(-1, inp_tensor.shape[-1])\n",
        "            pt_reshaped = pt_tensor.reshape(-1, pt_tensor.shape[-1])\n",
        "            qt_reshaped = qt_tensor.reshape(-1, qt_tensor.shape[-1])\n",
        "            min_tokens = min(inp_reshaped.shape[0], pt_reshaped.shape[0], qt_reshaped.shape[0])\n",
        "            if min_tokens <= 0: continue\n",
        "            inp_reshaped=inp_reshaped[:min_tokens];pt_reshaped=pt_reshaped[:min_tokens];qt_reshaped=qt_reshaped[:min_tokens]\n",
        "            gptq_instance.process_batch(inp=inp_reshaped, pt=pt_reshaped, qt=qt_reshaped)\n",
        "            del inp_tensor, pt_tensor, qt_tensor, inp_reshaped, pt_reshaped, qt_reshaped\n",
        "\n",
        "        except Exception as e:\n",
        "            log.error(f\"    Error processing batch {i} for layer {layer_name} Hessian calc: {e}\", exc_info=True)\n",
        "            continue\n",
        "\n",
        "    # --- Quantize the Layer ---\n",
        "    if not layer_has_valid_batch or gptq_instance.nsamples == 0:\n",
        "        log.warning(f\"  Skipping quantization for layer {layer_name}: No valid batches processed.\")\n",
        "        continue\n",
        "\n",
        "    log.info(f\"  Running final quantization for layer {layer_name} (nsamples={gptq_instance.nsamples})...\")\n",
        "    try:\n",
        "        gptq_instance.quantizer.configure(bits=quant_config.bits, sym=quant_config.sym)\n",
        "        results = gptq_instance.quantize(blocksize=quant_config.group_size)\n",
        "        Q, scale, zero, g_idx, duration, avg_loss, damp_used, nsamples = results\n",
        "        layer_module.weight.data = Q.to(layer_module.weight.device, dtype=layer_module.weight.dtype)\n",
        "        if hasattr(layer_module, 'q_scale'): del layer_module.q_scale\n",
        "        if hasattr(layer_module, 'q_zero'): del layer_module.q_zero\n",
        "        if hasattr(layer_module, 'q_g_idx'): del layer_module.q_g_idx\n",
        "        layer_module.register_buffer('q_scale', scale.to(layer_module.weight.device))\n",
        "        layer_module.register_buffer('q_zero', zero.to(layer_module.weight.device))\n",
        "        layer_module.register_buffer('q_g_idx', g_idx.to(layer_module.weight.device))\n",
        "        layer_module.quant_config = quant_config\n",
        "\n",
        "        log.info(f\"  Finished layer {layer_name}. Time={duration:.2f}s, Loss={avg_loss:.6f}, Damp={damp_used:.5f}, Ns={nsamples}\")\n",
        "        processed_layers_count += 1\n",
        "        del Q, scale, zero, g_idx; gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    except Exception as e:\n",
        "        log.error(f\"  ERROR quantizing layer {layer_name}: {e}\", exc_info=True)\n",
        "        raise e\n",
        "\n",
        "log.info(f\"\\nQuantization complete for {processed_layers_count} layers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:43:56.7862Z",
          "iopub.status.busy": "2025-04-29T19:43:56.785927Z",
          "iopub.status.idle": "2025-04-29T19:43:57.111688Z",
          "shell.execute_reply": "2025-04-29T19:43:57.11109Z",
          "shell.execute_reply.started": "2025-04-29T19:43:56.786179Z"
        },
        "id": "cQhcCzszKl3q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --- Clean up cached data ---\n",
        "log.info(\"Cleaning up cached calibration data...\")\n",
        "del cached_layer_inputs, cached_teacher_probs, pass2_batch_inputs # No student probs cache needed\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T19:43:57.112673Z",
          "iopub.status.busy": "2025-04-29T19:43:57.112464Z",
          "iopub.status.idle": "2025-04-29T19:44:34.300203Z",
          "shell.execute_reply": "2025-04-29T19:44:34.299367Z",
          "shell.execute_reply.started": "2025-04-29T19:43:57.112656Z"
        },
        "id": "815yZRoFKl3q",
        "outputId": "d3274d7a-117d-4754-82d6-f760cc5244a1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m  Saved Quantize Config: \n",
            "{\n",
            "  \"bits\": 8,\n",
            "  \"group_size\": 128,\n",
            "  \"desc_act\": true,\n",
            "  \"sym\": true,\n",
            "  \"lm_head\": false,\n",
            "  \"quant_method\": \"gptq\",\n",
            "  \"checkpoint_format\": \"gptq\",\n",
            "  \"pack_dtype\": \"int32\",\n",
            "  \"meta\": {\n",
            "    \"quantizer\": [\n",
            "      \"gptqmodel:3.0.0-dev\"\n",
            "    ],\n",
            "    \"uri\": \"https://github.com/modelcloud/gptqmodel\",\n",
            "    \"damp_percent\": 0.01,\n",
            "    \"damp_auto_increment\": 0.0025,\n",
            "    \"static_groups\": false,\n",
            "    \"true_sequential\": true,\n",
            "    \"mse\": 0.0,\n",
            "    \"v2\": false,\n",
            "    \"v2_alpha\": 0.25\n",
            "  }\n",
            "}\n",
            "Files in directory:\n",
            "config.json\n",
            "generation_config.json\n",
            "quantize_config.json\n",
            "Content of saved `generation_config.json`:\n",
            "{\n",
            "    \"bos_token_id\": 151643,\n",
            "    \"do_sample\": true,\n",
            "    \"eos_token_id\": [\n",
            "        151645,\n",
            "        151643\n",
            "    ],\n",
            "    \"pad_token_id\": 151643,\n",
            "    \"repetition_penalty\": 1.05,\n",
            "    \"temperature\": 1e-06,\n",
            "    \"transformers_version\": \"4.51.3\"\n",
            "}\n",
            "Content of saved `config.json`:\n",
            "{\n",
            "    \"architectures\": [\n",
            "        \"Qwen2_5_VLForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bos_token_id\": 151643,\n",
            "    \"eos_token_id\": 151645,\n",
            "    \"hidden_act\": \"silu\",\n",
            "    \"hidden_size\": 2048,\n",
            "    \"image_token_id\": 151655,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 11008,\n",
            "    \"max_position_embeddings\": 128000,\n",
            "    \"max_window_layers\": 70,\n",
            "    \"model_type\": \"qwen2_5_vl\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_hidden_layers\": 36,\n",
            "    \"num_key_value_heads\": 2,\n",
            "    \"quantization_config\": {\n",
            "        \"bits\": 8,\n",
            "        \"checkpoint_format\": \"gptq\",\n",
            "        \"desc_act\": true,\n",
            "        \"group_size\": 128,\n",
            "        \"lm_head\": false,\n",
            "        \"meta\": {\n",
            "            \"damp_auto_increment\": 0.0025,\n",
            "            \"damp_percent\": 0.01,\n",
            "            \"mse\": 0.0,\n",
            "            \"quantizer\": [\n",
            "                \"gptqmodel:3.0.0-dev\"\n",
            "            ],\n",
            "            \"static_groups\": false,\n",
            "            \"true_sequential\": true,\n",
            "            \"uri\": \"https://github.com/modelcloud/gptqmodel\",\n",
            "            \"v2\": false,\n",
            "            \"v2_alpha\": 0.25\n",
            "        },\n",
            "        \"pack_dtype\": \"int32\",\n",
            "        \"quant_method\": \"gptq\",\n",
            "        \"sym\": true\n",
            "    },\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_scaling\": {\n",
            "        \"mrope_section\": [\n",
            "            16,\n",
            "            24,\n",
            "            24\n",
            "        ],\n",
            "        \"rope_type\": \"default\",\n",
            "        \"type\": \"default\"\n",
            "    },\n",
            "    \"rope_theta\": 1000000.0,\n",
            "    \"sliding_window\": 32768,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"torch_dtype\": \"bfloat16\",\n",
            "    \"transformers_version\": \"4.51.3\",\n",
            "    \"use_cache\": true,\n",
            "    \"use_sliding_window\": false,\n",
            "    \"video_token_id\": 151656,\n",
            "    \"vision_config\": {\n",
            "        \"depth\": 32,\n",
            "        \"fullatt_block_indexes\": [\n",
            "            7,\n",
            "            15,\n",
            "            23,\n",
            "            31\n",
            "        ],\n",
            "        \"hidden_act\": \"silu\",\n",
            "        \"hidden_size\": 1280,\n",
            "        \"in_channels\": 3,\n",
            "        \"in_chans\": 3,\n",
            "        \"intermediate_size\": 3420,\n",
            "        \"model_type\": \"qwen2_5_vl\",\n",
            "        \"num_heads\": 16,\n",
            "        \"out_hidden_size\": 2048,\n",
            "        \"patch_size\": 14,\n",
            "        \"spatial_merge_size\": 2,\n",
            "        \"spatial_patch_size\": 14,\n",
            "        \"temporal_patch_size\": 2,\n",
            "        \"tokens_per_second\": 2,\n",
            "        \"torch_dtype\": \"bfloat16\",\n",
            "        \"window_size\": 112\n",
            "    },\n",
            "    \"vision_end_token_id\": 151653,\n",
            "    \"vision_start_token_id\": 151652,\n",
            "    \"vision_token_id\": 151654,\n",
            "    \"vocab_size\": 151936\n",
            "}\n",
            "\u001b[36mDEBUG\u001b[0m Received safetensors_metadata: {'format': 'pt'}                                              \n",
            "\u001b[32mINFO\u001b[0m  Pre-Quantized model size: 7161.46MB, 6.99GB                                                  \n",
            "\u001b[32mINFO\u001b[0m  Quantized model size: 7389.63MB, 7.22GB                                                      \n",
            "\u001b[32mINFO\u001b[0m  Size difference: -228.16MB, -0.22GB - -3.19%                                                 \n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL: Save Quantized Model and Processor\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import logging \n",
        "log = logging.getLogger(\"SaveModel\")\n",
        "if not log.hasHandlers():\n",
        "     logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "if 'processed_layers_count' not in locals():\n",
        "     log.warning(\"'processed_layers_count' not found. Assuming model state is quantized.\")\n",
        "     processed_layers_count = 1 \n",
        "\n",
        "if 'model_gptq' not in locals() or model_gptq is None:\n",
        "    log.error(\"Variable 'model_gptq' does not exist. Cannot save model.\")\n",
        "    raise NameError(\"model_gptq not defined. Was the previous cell run successfully?\")\n",
        "\n",
        "if processed_layers_count > 0:\n",
        "    log.info(f\"Manually setting quantized flag to True as {processed_layers_count} layers were processed.\")\n",
        "    if hasattr(model_gptq, 'quantized'):\n",
        "        model_gptq.quantized = True\n",
        "    else:\n",
        "        log.warning(\"model_gptq object does not have a 'quantized' attribute to set.\")\n",
        "    try:\n",
        "        from gptqmodel.nn_modules.qlinear.exllamav2 import ExllamaV2QuantLinear \n",
        "        log.info(f\"Attempting to set qlinear_kernel to {ExllamaV2QuantLinear}\")\n",
        "        model_gptq.qlinear_kernel = ExllamaV2QuantLinear\n",
        "    except ImportError:\n",
        "        log.error(\"Could not import the assumed QuantLinear kernel (e.g., ExllamaV2QuantLinear).\")\n",
        "        try:\n",
        "            from gptqmodel.quantization.config import FORMAT\n",
        "            if quant_config.format == FORMAT.GPTQ:\n",
        "                 log.error(\"qlinear_kernel type could not be determined, which might cause issues saving in GPTQ v1 format.\")\n",
        "                 pass # Proceed with warning for now\n",
        "            else:\n",
        "                 log.warning(f\"qlinear_kernel not set, but format is {quant_config.format}. Conversion might be skipped.\")\n",
        "        except ImportError:\n",
        "            log.warning(\"Could not import FORMAT enum to check config format. Proceeding without setting qlinear_kernel.\")\n",
        "        except NameError:\n",
        "             log.warning(\"'quant_config' not defined in this scope. Cannot check format for qlinear_kernel necessity.\")\n",
        "\n",
        "    except AttributeError:\n",
        "        log.warning(\"model_gptq object does not have a 'qlinear_kernel' attribute to set.\")\n",
        "    log.info(f\"Saving augmented quantized model to: {quant_path}\")\n",
        "    try:\n",
        "        os.makedirs(quant_path, exist_ok=True) \n",
        "        model_gptq.save(quant_path)\n",
        "        log.info(\"Model saved successfully.\")\n",
        "        if processor is not None:\n",
        "            processor.save_pretrained(quant_path)\n",
        "            log.info(\"Processor saved successfully.\")\n",
        "        else:\n",
        "            log.warning(\"Processor object not found, skipping processor save.\")\n",
        "    except Exception as e:\n",
        "        log.error(f\"Error saving model or processor: {e}\", exc_info=True)\n",
        "        raise \n",
        "else:\n",
        "    log.error(\"Cannot save model because no layers were quantized (processed_layers_count=0).\")\n",
        "\n",
        "log.info(\"--- Saving Cell Finished ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-29T20:56:49.265594Z",
          "iopub.status.busy": "2025-04-29T20:56:49.265019Z",
          "iopub.status.idle": "2025-04-29T20:58:08.756479Z",
          "shell.execute_reply": "2025-04-29T20:58:08.755765Z",
          "shell.execute_reply.started": "2025-04-29T20:56:49.265571Z"
        },
        "id": "f3bU_OCUKl3r",
        "outputId": "de2b11b0-f151-445b-b664-2b2467a1811b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "from_quantized: adapter: None\n",
            "\u001b[32mINFO\u001b[0m  Loader: Auto dtype (native bfloat16): `torch.bfloat16`                                       \n",
            "\u001b[32mINFO\u001b[0m  Estimated Quantization BPW (bits per weight): 8.31875 bpw, based on [bits: 8, group_size: 128]\n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.0.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.0.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.0.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.0.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.0.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.1.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.1.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.1.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.1.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.1.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.2.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.2.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.2.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.2.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.2.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.3.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.3.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.3.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.3.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.3.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.4.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.4.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.4.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.4.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.4.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.5.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.5.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.5.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.5.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.5.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.6.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.6.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.6.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.6.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.6.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.7.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.7.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.7.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.7.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.7.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.8.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.8.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.8.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.8.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.8.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.9.attn.qkv is not quantized.                                         \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.9.attn.proj is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.9.mlp.gate_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.9.mlp.up_proj is not quantized.                                      \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.9.mlp.down_proj is not quantized.                                    \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.10.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.10.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.10.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.10.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.10.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.11.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.11.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.11.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.11.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.11.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.12.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.12.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.12.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.12.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.12.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.13.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.13.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.13.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.13.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.13.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.14.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.14.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.14.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.14.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.14.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.15.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.15.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.15.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.15.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.15.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.16.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.16.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.16.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.16.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.16.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.17.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.17.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.17.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.17.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.17.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.18.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.18.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.18.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.18.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.18.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.19.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.19.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.19.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.19.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.19.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.20.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.20.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.20.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.20.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.20.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.21.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.21.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.21.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.21.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.21.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.22.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.22.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.22.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.22.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.22.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.23.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.23.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.23.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.23.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.23.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.24.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.24.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.24.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.24.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.24.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.25.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.25.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.25.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.25.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.25.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.26.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.26.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.26.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.26.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.26.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.27.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.27.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.27.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.27.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.27.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.28.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.28.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.28.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.28.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.28.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.29.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.29.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.29.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.29.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.29.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.30.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.30.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.30.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.30.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.30.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.31.attn.qkv is not quantized.                                        \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.31.attn.proj is not quantized.                                       \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.31.mlp.gate_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.31.mlp.up_proj is not quantized.                                     \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.blocks.31.mlp.down_proj is not quantized.                                   \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.merger.mlp.0 is not quantized.                                              \n",
            "\u001b[32mINFO\u001b[0m  The layer visual.merger.mlp.2 is not quantized.                                              \n",
            "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `TorchQuantLinear`                                 \n",
            "\u001b[32mINFO\u001b[0m  Kernel: candidates -> `[TorchQuantLinear]`                                                   \n",
            "\u001b[32mINFO\u001b[0m  Kernel: selected -> `TorchQuantLinear`.                                                      \n",
            "\u001b[32mINFO\u001b[0m  Format: Converting `checkpoint_format` from `FORMAT.GPTQ` to internal `FORMAT.GPTQ_V2`.      \n",
            "\u001b[32mINFO\u001b[0m  Format: Conversion complete: 0.009794235229492188s                                           \n",
            "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `TorchQuantLinear`                                 \n",
            "\u001b[32mINFO\u001b[0m  Model: Loaded `generation_config`: GenerationConfig { 0:46:45 / 5:36:36 [5/36] 13.9%\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "\u001b[32mINFO\u001b[0m  Model: Auto-fixed `generation_config` mismatch between model and `generation_config.json`.   \n",
            "\u001b[32mINFO\u001b[0m  Model: Updated `generation_config`: GenerationConfig {0:46:46 / 5:36:43 [5/36] 13.9%\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"repetition_penalty\": 1.05,\n",
            "  \"temperature\": 1e-06\n",
            "}\n",
            "\n",
            "\u001b[32mINFO\u001b[0m  Kernel: loaded -> `[TorchQuantLinear]`                                                       \n",
            "Quantizing self_attn.o_proj in layer  [4 of 35] ██-----------------| 0:46:48 / 5:36:57 [5/36] 13.9%Prompt: Describe a cat in detail:\n",
            "Output: Describe a cat in detail:::::::::::::::::::::::::::::::::::::::::::::::::::\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL: Text-Only Inference (Simplified API based on Original Example)\n",
        "# ==============================================================================\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import gc\n",
        "import logging\n",
        "import os\n",
        "\n",
        "QUANTIZED_MODEL_PATH = \"/kaggle/working/Qwen_Augmented_Ideal_v1\" # <<< VERIFY/SET THIS PATH\n",
        "GPTQ_LIB_PATH = '/kaggle/input/gptq-2/ModelCloud-GPTQModel-82c494f' # <<< Path to library\n",
        "if GPTQ_LIB_PATH not in sys.path:\n",
        "    sys.path.append(GPTQ_LIB_PATH)\n",
        "\n",
        "from gptqmodel import GPTQModel \n",
        "log = logging.getLogger(\"TextInferenceSimple\")\n",
        "if not log.hasHandlers():\n",
        "     logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "if not os.path.isdir(QUANTIZED_MODEL_PATH):\n",
        "    log.error(f\"Saved model path does not exist or is not a directory: {QUANTIZED_MODEL_PATH}\")\n",
        "    raise FileNotFoundError(f\"Model directory not found at {QUANTIZED_MODEL_PATH}. Did the previous cell save correctly?\")\n",
        "if not os.path.isfile(os.path.join(QUANTIZED_MODEL_PATH, \"quantize_config.json\")):\n",
        "     log.warning(f\"quantize_config.json not found in: {QUANTIZED_MODEL_PATH}. Loading might fail or use defaults.\")\n",
        "log.info(\"--- Loading Quantized Model (Text-Only) ---\")\n",
        "model = None \n",
        "\n",
        "try:\n",
        "    target_device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    log.info(f\"Loading quantized model from: {QUANTIZED_MODEL_PATH} directly to device='{target_device}'\")\n",
        "    model = GPTQModel.load(\n",
        "        QUANTIZED_MODEL_PATH,\n",
        "        device_map=\"auto\",   \n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    log.info(\"Quantized model loaded.\")\n",
        "    if not hasattr(model, 'tokenizer') or model.tokenizer is None:\n",
        "        log.error(\"Loaded GPTQModel object does not have a valid .tokenizer attribute!\")\n",
        "        raise AttributeError(\"Cannot find tokenizer on loaded model object.\")\n",
        "    log.info(\"Tokenizer found on model object.\")\n",
        "    if model.tokenizer.pad_token is None:\n",
        "        model.tokenizer.pad_token = model.tokenizer.eos_token\n",
        "        log.warning(f\"Tokenizer pad_token was None, set to eos_token: {model.tokenizer.pad_token}\")\n",
        "    prompt = \"Describe a cat in detail:\"\n",
        "    log.info(f\"Using prompt: '{prompt}'\")\n",
        "    log.info(\"Generating output (text-only using model.generate)...\")\n",
        "    output_text = \"[Generation Failed or Error Occurred]\" \n",
        "    generated_ids = None\n",
        "    result_tokens = None \n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generate_output = model.generate(\n",
        "            prompt,\n",
        "            max_new_tokens=50, \n",
        "            do_sample=False,\n",
        "        )\n",
        "        log.info(\"Generation call complete.\")\n",
        "        if isinstance(generate_output, (list, tuple)) and len(generate_output) > 0 and isinstance(generate_output[0], torch.Tensor):\n",
        "            result_tokens = generate_output[0]\n",
        "            log.info(f\"Extracted result tokens tensor. Shape: {result_tokens.shape}\")\n",
        "            output_text = model.tokenizer.decode(result_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "            log.info(\"Decoding successful.\")\n",
        "        elif isinstance(generate_output, torch.Tensor):\n",
        "             log.warning(\"model.generate returned tensor directly, not list/tuple.\")\n",
        "             result_tokens = generate_output\n",
        "             if result_tokens.ndim > 1 and result_tokens.shape[0] == 1: result_tokens = result_tokens[0] # Remove batch dim\n",
        "             output_text = model.tokenizer.decode(result_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "             log.warning(\"Decoding full sequence, may include prompt.\")\n",
        "\n",
        "        else:\n",
        "            log.error(f\"model.generate returned unexpected type: {type(generate_output)}\")\n",
        "            output_text = \"[Unexpected Generate Output Type]\"\n",
        "        # --- >> END Decode Change << ---\n",
        "\n",
        "\n",
        "    # --- Print Result ---\n",
        "    log.info(\"\\n--- Generated Text Output ---\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Output: {output_text}\")\n",
        "    log.info(\"-----------------------------\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n!!! ERROR during loading or text-only inference: {type(e).__name__}: {e}\")\n",
        "    log.error(f\"\\nError during loading or text-only inference: {e}\", exc_info=True)\n",
        "\n",
        "# finally:\n",
        "#     # --- Cleanup ---\n",
        "#     log.info(\"Cleaning up text-only inference resources...\")\n",
        "#     del model, tokenizer # Use correct var names\n",
        "#     # Delete inputs if it was created in fallback logic\n",
        "#     if 'inputs' in locals(): del inputs\n",
        "#     if 'result_tokens' in locals(): del result_tokens\n",
        "#     if 'generate_output' in locals(): del generate_output\n",
        "#     gc.collect()\n",
        "#     if torch.cuda.is_available():\n",
        "#         torch.cuda.empty_cache()\n",
        "#     log.info(\"Cleanup finished.\")\n",
        "\n",
        "# log.info(\"--- Text-Only Inference Test Finished ---\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "hello1",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 7155573,
          "sourceId": 11425261,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7267124,
          "sourceId": 11589464,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7279190,
          "sourceId": 11605475,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7287146,
          "sourceId": 11616554,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
